Este proyecto implementa un traductor automático de LSM que captura movimientos corporales y de manos a través de una cámara, procesándolos con MediaPipe y clasificándolos mediante una red neuronal LSTM entrenada. El sistema está disponible en dos plataformas:

#Versión Desktop (Python): Para pruebas y desarrollo con cámara web
#Versión Móvil (Android): Aplicación nativa para uso portátil
